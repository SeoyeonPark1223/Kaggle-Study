{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13435,"databundleVersionId":331452,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aerial Cactus Identification - Modeling 2","metadata":{}},{"cell_type":"markdown","source":"Tutorial Link -> https://www.kaggle.com/code/werooring/ch11-modeling2","metadata":{}},{"cell_type":"markdown","source":"- Modeling 2\n    - In prev Modeling, we divided train/validation data in ratio 9 : 1\n    - Instead, use whole training data to train the model \n    ``` py\n     # divide train / validation Data\n     _, valid = train_test_split(labels, \n                               test_size = 0.1, # ratio; _ : valid = 9 : 1\n                               stratify = labels['has_cactus'],\n                               random_state = 50)\n                               \n     # create train / validation dataset\n     dataset_train = ImageDataset(df = labels, img_dir = 'train/', transform = transform_train)\n     dataset_valid = ImageDataset(df = valid, img_dir = 'train/', transform = transform_test)\n     ```\n     \n    ","metadata":{}},{"cell_type":"markdown","source":"**Fix Seed Value**","metadata":{}},{"cell_type":"code","source":"import torch # pytorch\nimport random\nimport numpy as np\nimport os\n\n# fix seed value\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed) \ntorch.backends.cudnn.deterministic = True \ntorch.backends.cudnn.benchmark = False    \ntorch.backends.cudnn.enabled = False      ","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:40.578477Z","iopub.execute_input":"2024-09-10T04:13:40.578760Z","iopub.status.idle":"2024-09-10T04:13:46.089014Z","shell.execute_reply.started":"2024-09-10T04:13:40.578727Z","shell.execute_reply":"2024-09-10T04:13:46.087940Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:46.092744Z","iopub.execute_input":"2024-09-10T04:13:46.093146Z","iopub.status.idle":"2024-09-10T04:13:46.149167Z","shell.execute_reply.started":"2024-09-10T04:13:46.093111Z","shell.execute_reply":"2024-09-10T04:13:46.147980Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:46.150888Z","iopub.execute_input":"2024-09-10T04:13:46.151864Z","iopub.status.idle":"2024-09-10T04:13:46.173067Z","shell.execute_reply.started":"2024-09-10T04:13:46.151814Z","shell.execute_reply":"2024-09-10T04:13:46.172173Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-10T04:13:46.175747Z","iopub.execute_input":"2024-09-10T04:13:46.176329Z","iopub.status.idle":"2024-09-10T04:13:46.500713Z","shell.execute_reply.started":"2024-09-10T04:13:46.176284Z","shell.execute_reply":"2024-09-10T04:13:46.499803Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/aerial-cactus-identification/sample_submission.csv\n/kaggle/input/aerial-cactus-identification/train.zip\n/kaggle/input/aerial-cactus-identification/test.zip\n/kaggle/input/aerial-cactus-identification/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv') # train data \nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:46.501861Z","iopub.execute_input":"2024-09-10T04:13:46.502252Z","iopub.status.idle":"2024-09-10T04:13:46.651834Z","shell.execute_reply.started":"2024-09-10T04:13:46.502219Z","shell.execute_reply":"2024-09-10T04:13:46.650874Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# unzip the zip file \n\nfrom zipfile import ZipFile\n\n# unzip training img data\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n\n# unzip test img data \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:46.653382Z","iopub.execute_input":"2024-09-10T04:13:46.654287Z","iopub.status.idle":"2024-09-10T04:13:49.543827Z","shell.execute_reply.started":"2024-09-10T04:13:46.654237Z","shell.execute_reply":"2024-09-10T04:13:49.542773Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Divide Train / Validation Data**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n_, valid = train_test_split(labels, \n                               test_size = 0.1, # ratio; _ : valid = 9 : 1\n                               stratify = labels['has_cactus'],\n                               random_state = 50)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:49.544907Z","iopub.execute_input":"2024-09-10T04:13:49.545198Z","iopub.status.idle":"2024-09-10T04:13:50.256466Z","shell.execute_reply.started":"2024-09-10T04:13:49.545166Z","shell.execute_reply":"2024-09-10T04:13:50.255659Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Define DataSet Class**","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset \n\nclass ImageDataset(Dataset):\n    # constructor\n    def __init__(self, df, img_dir = './', transform = None):\n        super().__init__()\n        self.df = df # train or validation dataset \n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1] # target value\n        \n        if self.transform is not None:\n            # if there's a transformer(변환기)\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:50.257585Z","iopub.execute_input":"2024-09-10T04:13:50.257994Z","iopub.status.idle":"2024-09-10T04:13:50.713378Z","shell.execute_reply.started":"2024-09-10T04:13:50.257961Z","shell.execute_reply":"2024-09-10T04:13:50.712442Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Define Image Transformer**","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Pad(32, padding_mode='symmetric'),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.Normalize((0.485, 0.456, 0.406),\n                                                           (0.229, 0.224, 0.225))])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test= transforms.Compose([transforms.ToTensor(),\n                                    transforms.Pad(32, padding_mode='symmetric'),\n                                    transforms.Normalize((0.485, 0.456, 0.406),\n                                                         (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:50.714559Z","iopub.execute_input":"2024-09-10T04:13:50.714834Z","iopub.status.idle":"2024-09-10T04:13:52.523285Z","shell.execute_reply.started":"2024-09-10T04:13:50.714805Z","shell.execute_reply":"2024-09-10T04:13:52.522323Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Create Dataset and Data Loader**","metadata":{}},{"cell_type":"code","source":"# create train / validation dataset\ndataset_train = ImageDataset(df = labels, img_dir = 'train/', transform = transform_train)\ndataset_valid = ImageDataset(df = valid, img_dir = 'train/', transform = transform_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.524619Z","iopub.execute_input":"2024-09-10T04:13:52.525153Z","iopub.status.idle":"2024-09-10T04:13:52.530438Z","shell.execute_reply.started":"2024-09-10T04:13:52.525107Z","shell.execute_reply":"2024-09-10T04:13:52.529456Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nloader_train = DataLoader(dataset = dataset_train, batch_size = 32, shuffle = True)\nloader_valid = DataLoader(dataset = dataset_valid, batch_size = 32, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.533739Z","iopub.execute_input":"2024-09-10T04:13:52.534029Z","iopub.status.idle":"2024-09-10T04:13:52.540282Z","shell.execute_reply.started":"2024-09-10T04:13:52.533998Z","shell.execute_reply":"2024-09-10T04:13:52.539390Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__() # successed nn.Module's __init__() method call \n        \n        self.layer1 = nn.Sequential(nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 2),\n                                   nn.BatchNorm2d(32), # batch normalization \n                                   nn.LeakyReLU(), # Leaky ReLU for activation function\n                                   nn.MaxPool2d(kernel_size = 2))\n        \n        self.layer2 = nn.Sequential(nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 2),\n                                   nn.BatchNorm2d(64),\n                                   nn.LeakyReLU(),\n                                   nn.MaxPool2d(kernel_size = 2))\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 2),\n                                   nn.BatchNorm2d(128),\n                                   nn.LeakyReLU(),\n                                   nn.MaxPool2d(kernel_size = 2))\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 2),\n                                   nn.BatchNorm2d(256),\n                                   nn.LeakyReLU(),\n                                   nn.MaxPool2d(kernel_size = 2))\n        \n        self.layer5 = nn.Sequential(nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 2),\n                                   nn.BatchNorm2d(512),\n                                   nn.LeakyReLU(),\n                                   nn.MaxPool2d(kernel_size = 2))\n        \n        self.avg_pool = nn.AvgPool2d(kernel_size = 4)\n        \n        self.fc1 = nn.Linear(in_features = 512 * 1 * 1, out_features = 64)\n        self.fc2 = nn.Linear(in_features = 64, out_features = 2)\n        \n    # forward propagation\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512 * 1 *1) # flattening\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.541184Z","iopub.execute_input":"2024-09-10T04:13:52.541481Z","iopub.status.idle":"2024-09-10T04:13:52.554822Z","shell.execute_reply.started":"2024-09-10T04:13:52.541445Z","shell.execute_reply":"2024-09-10T04:13:52.553943Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.555752Z","iopub.execute_input":"2024-09-10T04:13:52.556014Z","iopub.status.idle":"2024-09-10T04:13:52.905809Z","shell.execute_reply.started":"2024-09-10T04:13:52.555985Z","shell.execute_reply":"2024-09-10T04:13:52.904914Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"markdown","source":"**Set Loss Function & Optimizer**","metadata":{}},{"cell_type":"code","source":"# loss function -> use cross entropy (because it's classification problem)\ncriterion = nn.CrossEntropyLoss()\n\n# optimizer -> finding optimized weight algorithm\n# Adamax (better ver of Adam)\n\noptimizer = torch.optim.Adamax(model.parameters(), lr = 0.00006)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.906853Z","iopub.execute_input":"2024-09-10T04:13:52.907141Z","iopub.status.idle":"2024-09-10T04:13:52.915687Z","shell.execute_reply.started":"2024-09-10T04:13:52.907110Z","shell.execute_reply":"2024-09-10T04:13:52.914558Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Train Model**","metadata":{}},{"cell_type":"code","source":"epochs = 70 # increase epoch to 70\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    \n    for images, labels in loader_train: # repeat count = len(loader_train)\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        epoch_loss += loss.item()\n        loss.backward()\n        \n        optimizer.step() # new weight = original weight - (learning rate * gradient)\n        \n    print(f'epoch [{epoch+1}/{epochs}] - loss: {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T04:13:52.916969Z","iopub.execute_input":"2024-09-10T04:13:52.917265Z","iopub.status.idle":"2024-09-10T05:00:21.283783Z","shell.execute_reply.started":"2024-09-10T04:13:52.917231Z","shell.execute_reply":"2024-09-10T05:00:21.282819Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"epoch [1/70] - loss: 0.1272\nepoch [2/70] - loss: 0.0645\nepoch [3/70] - loss: 0.0494\nepoch [4/70] - loss: 0.0379\nepoch [5/70] - loss: 0.0343\nepoch [6/70] - loss: 0.0300\nepoch [7/70] - loss: 0.0282\nepoch [8/70] - loss: 0.0257\nepoch [9/70] - loss: 0.0247\nepoch [10/70] - loss: 0.0224\nepoch [11/70] - loss: 0.0210\nepoch [12/70] - loss: 0.0190\nepoch [13/70] - loss: 0.0208\nepoch [14/70] - loss: 0.0184\nepoch [15/70] - loss: 0.0155\nepoch [16/70] - loss: 0.0159\nepoch [17/70] - loss: 0.0155\nepoch [18/70] - loss: 0.0152\nepoch [19/70] - loss: 0.0147\nepoch [20/70] - loss: 0.0131\nepoch [21/70] - loss: 0.0130\nepoch [22/70] - loss: 0.0111\nepoch [23/70] - loss: 0.0116\nepoch [24/70] - loss: 0.0113\nepoch [25/70] - loss: 0.0119\nepoch [26/70] - loss: 0.0105\nepoch [27/70] - loss: 0.0106\nepoch [28/70] - loss: 0.0105\nepoch [29/70] - loss: 0.0105\nepoch [30/70] - loss: 0.0092\nepoch [31/70] - loss: 0.0093\nepoch [32/70] - loss: 0.0102\nepoch [33/70] - loss: 0.0091\nepoch [34/70] - loss: 0.0092\nepoch [35/70] - loss: 0.0083\nepoch [36/70] - loss: 0.0088\nepoch [37/70] - loss: 0.0082\nepoch [38/70] - loss: 0.0072\nepoch [39/70] - loss: 0.0065\nepoch [40/70] - loss: 0.0068\nepoch [41/70] - loss: 0.0069\nepoch [42/70] - loss: 0.0071\nepoch [43/70] - loss: 0.0076\nepoch [44/70] - loss: 0.0063\nepoch [45/70] - loss: 0.0063\nepoch [46/70] - loss: 0.0063\nepoch [47/70] - loss: 0.0061\nepoch [48/70] - loss: 0.0062\nepoch [49/70] - loss: 0.0053\nepoch [50/70] - loss: 0.0056\nepoch [51/70] - loss: 0.0074\nepoch [52/70] - loss: 0.0046\nepoch [53/70] - loss: 0.0051\nepoch [54/70] - loss: 0.0053\nepoch [55/70] - loss: 0.0039\nepoch [56/70] - loss: 0.0056\nepoch [57/70] - loss: 0.0048\nepoch [58/70] - loss: 0.0052\nepoch [59/70] - loss: 0.0045\nepoch [60/70] - loss: 0.0033\nepoch [61/70] - loss: 0.0046\nepoch [62/70] - loss: 0.0041\nepoch [63/70] - loss: 0.0046\nepoch [64/70] - loss: 0.0028\nepoch [65/70] - loss: 0.0035\nepoch [66/70] - loss: 0.0037\nepoch [67/70] - loss: 0.0046\nepoch [68/70] - loss: 0.0029\nepoch [69/70] - loss: 0.0030\nepoch [70/70] - loss: 0.0038\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Performance Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport numpy as np\n\ntrue_list = []\npreds_list = []\n\nmodel.eval() # evaluation stage -> won't apply dropout \n\nwith torch.no_grad(): # inactivate calculating gradient (no need to calculate gradient in evaluation step)\n    for images, labels in loader_valid:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        # why back to cpu? -> roc_auc is sklearn -> it can't perform on GPU\n        preds = torch.softmax(outputs.cpu(), dim = 1)[:, 1] # preds probability\n        true = labels.cpu() # true val\n        \n        # have to convert preds and true tensors to original python array or numpy array\n        preds_list.extend(preds.tolist())\n        true_list.extend(true.tolist())\n        \nprint(f'validation data ROC AUC: {roc_auc_score(true_list, preds_list):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:00:21.285125Z","iopub.execute_input":"2024-09-10T05:00:21.285534Z","iopub.status.idle":"2024-09-10T05:00:23.238765Z","shell.execute_reply.started":"2024-09-10T05:00:21.285487Z","shell.execute_reply":"2024-09-10T05:00:23.237780Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"validation data ROC AUC: 1.0000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Prediction and Submit Result","metadata":{}},{"cell_type":"code","source":"# create test dataset and data loader\ndataset_test = ImageDataset(df = submission, img_dir = 'test/', transform = transform_test)\nloader_test = DataLoader(dataset = dataset_test, batch_size = 32, shuffle = False)\n\nmodel.eval()\n\npreds = []\n\nwith torch.no_grad():\n    for images, _ in loader_test:\n        images = images.to(device)\n        \n        outputs = model(images)\n        \n        preds_part = torch.softmax(outputs.cpu(), dim = 1)[:, 1].tolist()\n        \n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:00:23.240239Z","iopub.execute_input":"2024-09-10T05:00:23.240566Z","iopub.status.idle":"2024-09-10T05:00:28.298323Z","shell.execute_reply.started":"2024-09-10T05:00:23.240531Z","shell.execute_reply":"2024-09-10T05:00:28.295935Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:00:28.302002Z","iopub.execute_input":"2024-09-10T05:00:28.302366Z","iopub.status.idle":"2024-09-10T05:00:28.338772Z","shell.execute_reply.started":"2024-09-10T05:00:28.302322Z","shell.execute_reply":"2024-09-10T05:00:28.337762Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# delete entire directory \nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T05:00:28.340294Z","iopub.execute_input":"2024-09-10T05:00:28.341023Z","iopub.status.idle":"2024-09-10T05:00:28.970286Z","shell.execute_reply.started":"2024-09-10T05:00:28.340979Z","shell.execute_reply":"2024-09-10T05:00:28.969516Z"},"trusted":true},"execution_count":19,"outputs":[]}]}