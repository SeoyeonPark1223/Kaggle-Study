{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Plant Pathology - Baseline","metadata":{}},{"cell_type":"markdown","source":"Tutorial Link -> https://www.kaggle.com/code/werooring/ch12-baseline","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Fix Seed Value and Set GPU","metadata":{}},{"cell_type":"markdown","source":"**Fix Seed Value**","metadata":{}},{"cell_type":"code","source":"import torch # pytorch\nimport random\nimport numpy as np\nimport os\n\n# fix seed value\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed) \ntorch.backends.cudnn.deterministic = True \ntorch.backends.cudnn.benchmark = False    \ntorch.backends.cudnn.enabled = False      ","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:06:54.916733Z","iopub.execute_input":"2024-09-10T15:06:54.917058Z","iopub.status.idle":"2024-09-10T15:06:59.142501Z","shell.execute_reply.started":"2024-09-10T15:06:54.917023Z","shell.execute_reply":"2024-09-10T15:06:59.141295Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Set GPU**","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:07:06.331835Z","iopub.execute_input":"2024-09-10T15:07:06.332757Z","iopub.status.idle":"2024-09-10T15:07:06.393017Z","shell.execute_reply.started":"2024-09-10T15:07:06.332715Z","shell.execute_reply":"2024-09-10T15:07:06.392019Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Prep Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:08:10.962244Z","iopub.execute_input":"2024-09-10T15:08:10.962655Z","iopub.status.idle":"2024-09-10T15:08:11.439999Z","shell.execute_reply.started":"2024-09-10T15:08:10.962615Z","shell.execute_reply":"2024-09-10T15:08:11.438939Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Divide Train / Validation Data**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train, \n                               test_size = 0.1, # ratio; train : valid = 9 : 1\n                               stratify = train[['healthy', 'multiple_diseases', 'rust', 'scab']], # maintaning ratio in each data set\n                               random_state = 50)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:10:12.688077Z","iopub.execute_input":"2024-09-10T15:10:12.689426Z","iopub.status.idle":"2024-09-10T15:10:12.870413Z","shell.execute_reply.started":"2024-09-10T15:10:12.689366Z","shell.execute_reply":"2024-09-10T15:10:12.869441Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Define Dataset Class**","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset \nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # constructor\n    # if dataset is for test, set is_test = True \n    # else if it's for train or validation, set is_test = False\n    def __init__(self, df, img_dir = './', transform = None, is_test = False):\n        super().__init__()\n        self.df = df # train or validation dataset \n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id + '.jpg'\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1] # target value\n        \n        if self.transform is not None:\n            # if there's a transformer(변환기)\n            # use albumentations module's transformer\n            image = self.transform(image=image)['image'] \n        \n        # if test data, return only image data / if not, also return target value\n        if self.is_test:\n            return image\n        else:\n            # idx of target value with biggest value among 4\n            label = np.argmax(self.df.iloc[idx, 1:5])\n            return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:18:09.988556Z","iopub.execute_input":"2024-09-10T15:18:09.989336Z","iopub.status.idle":"2024-09-10T15:18:10.271301Z","shell.execute_reply.started":"2024-09-10T15:18:09.989293Z","shell.execute_reply":"2024-09-10T15:18:10.270420Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Define Image Transformer**","metadata":{}},{"cell_type":"code","source":"# modules\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:19:18.924889Z","iopub.execute_input":"2024-09-10T15:19:18.925473Z","iopub.status.idle":"2024-09-10T15:19:18.932654Z","shell.execute_reply.started":"2024-09-10T15:19:18.925430Z","shell.execute_reply":"2024-09-10T15:19:18.931667Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# transformer for training data\ntransform_train = A.Compose([\n    A.Resize(450, 650),       \n    A.RandomBrightnessContrast(brightness_limit=0.2, \n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    \n    A.HorizontalFlip(p=0.5),  \n    A.ShiftScaleRotate(      \n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),  \n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), \n    A.Normalize(),             \n    ToTensorV2()              \n])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:25:26.760941Z","iopub.execute_input":"2024-09-10T15:25:26.761338Z","iopub.status.idle":"2024-09-10T15:25:26.770866Z","shell.execute_reply.started":"2024-09-10T15:25:26.761299Z","shell.execute_reply":"2024-09-10T15:25:26.769921Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# transformer for validating / testing data\ntransform_test = A.Compose([\n    A.Resize(450, 650),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:26:50.885592Z","iopub.execute_input":"2024-09-10T15:26:50.886355Z","iopub.status.idle":"2024-09-10T15:26:50.891388Z","shell.execute_reply.started":"2024-09-10T15:26:50.886312Z","shell.execute_reply":"2024-09-10T15:26:50.890395Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Create Dataset and Data Loader**","metadata":{}},{"cell_type":"code","source":"# create train / validation dataset\nimg_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(df = train, img_dir = img_dir, transform = transform_train)\ndataset_valid = ImageDataset(df = valid, img_dir = img_dir, transform = transform_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:28:29.294514Z","iopub.execute_input":"2024-09-10T15:28:29.294946Z","iopub.status.idle":"2024-09-10T15:28:29.300223Z","shell.execute_reply.started":"2024-09-10T15:28:29.294905Z","shell.execute_reply":"2024-09-10T15:28:29.299235Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"- Use Multi-processing\n    - Have to fix Data Loader's seed value -> use `seed_worker`","metadata":{}},{"cell_type":"code","source":"def seed_worker(worder_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:30:37.175656Z","iopub.execute_input":"2024-09-10T15:30:37.176088Z","iopub.status.idle":"2024-09-10T15:30:37.184122Z","shell.execute_reply.started":"2024-09-10T15:30:37.176045Z","shell.execute_reply":"2024-09-10T15:30:37.182900Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7b696c341810>"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size= batch_size, \n                         shuffle = True, worker_init_fn = seed_worker,\n                         generator = g, num_workers = 2)\nloader_valid = DataLoader(dataset_valid, batch_size= batch_size,\n                         shuffle = False, worker_init_fn = seed_worker,\n                         generator = g, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:32:23.481326Z","iopub.execute_input":"2024-09-10T15:32:23.481792Z","iopub.status.idle":"2024-09-10T15:32:23.488399Z","shell.execute_reply.started":"2024-09-10T15:32:23.481722Z","shell.execute_reply":"2024-09-10T15:32:23.487415Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 3. Create Model","metadata":{}},{"cell_type":"markdown","source":"- Use pretrained model\n    - Use torchvision.models module\n    - Use pretrainedmodels module\n    - Use self-constructed / searched module -> EfficientNet\n- Perform transfer learning\n    - Transfer learning: re-training pretrained model on similar but difference area","metadata":{}},{"cell_type":"markdown","source":"**Create EfficientNet Model**","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:39:21.339879Z","iopub.execute_input":"2024-09-10T15:39:21.340883Z","iopub.status.idle":"2024-09-10T15:39:39.562509Z","shell.execute_reply.started":"2024-09-10T15:39:21.340821Z","shell.execute_reply":"2024-09-10T15:39:39.561499Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=17fca8224587550d69ae28702e83470384e075bcbb738b92845570fce207109e\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# import EfficientNet model\nfrom efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:40:30.183726Z","iopub.execute_input":"2024-09-10T15:40:30.184420Z","iopub.status.idle":"2024-09-10T15:40:30.198270Z","shell.execute_reply.started":"2024-09-10T15:40:30.184365Z","shell.execute_reply":"2024-09-10T15:40:30.197231Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# call pre-trained efficientnet-b7 model\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes = 4) # num_classes: final output count\n\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:48:54.580328Z","iopub.execute_input":"2024-09-10T15:48:54.580780Z","iopub.status.idle":"2024-09-10T15:48:57.558563Z","shell.execute_reply.started":"2024-09-10T15:48:54.580720Z","shell.execute_reply":"2024-09-10T15:48:57.557689Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n100%|██████████| 254M/254M [00:01<00:00, 221MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. Train Model and Validation","metadata":{}},{"cell_type":"markdown","source":"**Set Loss Function and Optimizer**","metadata":{}},{"cell_type":"code","source":"# loss function: classification prob -> use CrossEntropyLoss()\nimport torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:50:25.989910Z","iopub.execute_input":"2024-09-10T15:50:25.990634Z","iopub.status.idle":"2024-09-10T15:50:25.995809Z","shell.execute_reply.started":"2024-09-10T15:50:25.990579Z","shell.execute_reply":"2024-09-10T15:50:25.994700Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# optimizer: AdamW (Adam + weight decay (prevent over-fitting))\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:51:57.647233Z","iopub.execute_input":"2024-09-10T15:51:57.647977Z","iopub.status.idle":"2024-09-10T15:51:58.625156Z","shell.execute_reply.started":"2024-09-10T15:51:57.647938Z","shell.execute_reply":"2024-09-10T15:51:58.624326Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"**Train and Performance Validation**","metadata":{}},{"cell_type":"markdown","source":"- Performance Validation\n    - Instead of validating after perform training all epochs, validate after **every** epoch\n    - It takes longer time, but it can check there's no overfitting while training ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom tqdm.notebook import tqdm # process bar\nepochs = 5\n\nfor epoch in range(epochs):\n    # train\n    model.train()\n    epoch_train_loss = 0\n    \n    for images, labels in tqdm(loader_train):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        epoch_train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        \n    print(f'epoch [{epoch+1}/{epochs}] - loss val from training data: {epoch_train_loss/len(loader_train):.4f}')\n    \n    # validation\n    model.eval()\n    epoch_valid_loss = 0\n    preds_list = []\n    true_onehot_list = []\n    \n    with torch.no_grad():\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy()\n#             true_onehot = torch.eye(4)[labels].cpu().numpy()\n            true_onehot = torch.eye(4).to(labels.device)[labels].cpu().numpy()\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n            \n    print(f'epoch [{epoch+1}/{epochs}] - loss val from validation data: {epoch_valid_loss/len(loader_valid):.4f} / Validation Data ROC AUC: {roc_auc_score(true_onehot_list, preds_list):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T16:21:36.952267Z","iopub.execute_input":"2024-09-10T16:21:36.952706Z","iopub.status.idle":"2024-09-10T16:28:57.194989Z","shell.execute_reply.started":"2024-09-10T16:21:36.952666Z","shell.execute_reply":"2024-09-10T16:28:57.193441Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/410 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393880b172cf45589ff21f9f11519e2b"}},"metadata":{}},{"name":"stdout","text":"epoch [1/5] - loss val from training data: 0.3413\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m epoch_valid_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     38\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mcpu(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 39\u001b[0m true_onehot \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     40\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[1;32m     41\u001b[0m true_onehot_list\u001b[38;5;241m.\u001b[39mextend(true_onehot)\n","\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"],"ename":"RuntimeError","evalue":"indices should be either on cpu or on the same device as the indexed tensor (cpu)","output_type":"error"}]},{"cell_type":"markdown","source":"## 5. Predication and Submit Result","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predication**","metadata":{}},{"cell_type":"code","source":"model.eval()\n\npreds = np.zeros((len(test), 4))\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        \n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Submit Result**","metadata":{}},{"cell_type":"code","source":"submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}