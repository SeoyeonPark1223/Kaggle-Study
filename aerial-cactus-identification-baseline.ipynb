{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13435,"databundleVersionId":331452,"sourceType":"competition"}],"dockerImageVersionId":30123,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aerial Cactus Identification - Baseline","metadata":{"papermill":{"duration":0.01747,"end_time":"2021-07-31T06:57:35.274085","exception":false,"start_time":"2021-07-31T06:57:35.256615","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Tutorial Link -> https://www.kaggle.com/code/werooring/ch11-baseline","metadata":{}},{"cell_type":"markdown","source":"**Fix Seed Value**","metadata":{}},{"cell_type":"code","source":"import torch # pytorch\nimport random\nimport numpy as np\nimport os\n\n# fix seed value\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed) \ntorch.backends.cudnn.deterministic = True \ntorch.backends.cudnn.benchmark = False    \ntorch.backends.cudnn.enabled = False      ","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:33.247732Z","iopub.execute_input":"2024-09-10T01:34:33.248115Z","iopub.status.idle":"2024-09-10T01:34:33.258729Z","shell.execute_reply.started":"2024-09-10T01:34:33.248079Z","shell.execute_reply":"2024-09-10T01:34:33.257767Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Set GPU Environment**","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:33.260744Z","iopub.execute_input":"2024-09-10T01:34:33.261064Z","iopub.status.idle":"2024-09-10T01:34:33.268584Z","shell.execute_reply.started":"2024-09-10T01:34:33.261017Z","shell.execute_reply":"2024-09-10T01:34:33.267624Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:33.269896Z","iopub.execute_input":"2024-09-10T01:34:33.270159Z","iopub.status.idle":"2024-09-10T01:34:33.283340Z","shell.execute_reply.started":"2024-09-10T01:34:33.270129Z","shell.execute_reply":"2024-09-10T01:34:33.282328Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}]},{"cell_type":"markdown","source":"**Prep Data**","metadata":{}},{"cell_type":"markdown","source":"1. Divide train / validation data\n2. Define DataSet class\n3. Create DataSet\n4. Create DataLoader\n\n- What is DataSet class & DataLoader's job?\n    - Provide data in mini-batch unit which is needed for deep learning model's training ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv') # train data \nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:33.284782Z","iopub.execute_input":"2024-09-10T01:34:33.285063Z","iopub.status.idle":"2024-09-10T01:34:33.331573Z","shell.execute_reply.started":"2024-09-10T01:34:33.285031Z","shell.execute_reply":"2024-09-10T01:34:33.330718Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# unzip the zip file \n\nfrom zipfile import ZipFile\n\n# unzip training img data\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n\n# unzip test img data \nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:33.334627Z","iopub.execute_input":"2024-09-10T01:34:33.334989Z","iopub.status.idle":"2024-09-10T01:34:37.824827Z","shell.execute_reply.started":"2024-09-10T01:34:33.334943Z","shell.execute_reply":"2024-09-10T01:34:37.823869Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Divide Train / Validation Data**","metadata":{}},{"cell_type":"markdown","source":"- stratify\n    - Stratify refers to the process of ensuring that each class or category in a dataset is proportionally represented when splitting the data\n    - ex) stratify = labels['has_cactus'] in next cell -> target value ratio was 1 : 3 -> this ratio is also applied in each train / validation data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(labels, \n                               test_size = 0.1, # ratio; train : valid = 9 : 1\n                               stratify = labels['has_cactus'],\n                               random_state = 50)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.827049Z","iopub.execute_input":"2024-09-10T01:34:37.827427Z","iopub.status.idle":"2024-09-10T01:34:37.854406Z","shell.execute_reply.started":"2024-09-10T01:34:37.827378Z","shell.execute_reply":"2024-09-10T01:34:37.853407Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# train data count : validation data count = 9 : 1\nprint('train data count: ', len(train))\nprint('validation data count: ', len(valid))","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.855745Z","iopub.execute_input":"2024-09-10T01:34:37.855989Z","iopub.status.idle":"2024-09-10T01:34:37.862190Z","shell.execute_reply.started":"2024-09-10T01:34:37.855961Z","shell.execute_reply":"2024-09-10T01:34:37.861203Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"train data count:  15750\nvalidation data count:  1750\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Define DataSet Class**","metadata":{}},{"cell_type":"markdown","source":"- Use Dataset class provided by pytorch\n- Have to overide `__len__()` and `__getitem()__`\n    - `__len__()`: return Dataset's size\n    - `__getitem()__`: return data of corresponding index","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset \n\nclass ImageDataset(Dataset):\n    # constructor\n    def __init__(self, df, img_dir = './', transform = None):\n        super().__init__()\n        self.df = df # train or validation dataset \n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.df.iloc[idx, 1] # target value\n        \n        if self.transform is not None:\n            # if there's a transformer(변환기)\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.863427Z","iopub.execute_input":"2024-09-10T01:34:37.863708Z","iopub.status.idle":"2024-09-10T01:34:37.875454Z","shell.execute_reply.started":"2024-09-10T01:34:37.863677Z","shell.execute_reply":"2024-09-10T01:34:37.874479Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"**Create Dataset**","metadata":{}},{"cell_type":"code","source":"# transform img data to tensor type\nfrom torchvision import transforms\n\ntransform = transforms.ToTensor()\n# (width pixel num, height pixel num, channel num) -> (channel num, width pixel num, height pixel num)\n# if there's a batch -> (batch size, channel num, width pixel num, height pixel num)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.876776Z","iopub.execute_input":"2024-09-10T01:34:37.877059Z","iopub.status.idle":"2024-09-10T01:34:37.891945Z","shell.execute_reply.started":"2024-09-10T01:34:37.877028Z","shell.execute_reply":"2024-09-10T01:34:37.890852Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# create train / validation dataset\ndataset_train = ImageDataset(df = train, img_dir = 'train/', transform = transform)\ndataset_valid = ImageDataset(df = valid, img_dir = 'train/', transform = transform)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.893553Z","iopub.execute_input":"2024-09-10T01:34:37.893957Z","iopub.status.idle":"2024-09-10T01:34:37.903000Z","shell.execute_reply.started":"2024-09-10T01:34:37.893908Z","shell.execute_reply":"2024-09-10T01:34:37.902041Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"**Create Data Loader**","metadata":{}},{"cell_type":"markdown","source":"- Data Loader\n    - Fetch data by designated batch size ","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nloader_train = DataLoader(dataset = dataset_train, batch_size = 32, shuffle = True)\nloader_valid = DataLoader(dataset = dataset_valid, batch_size = 32, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.904356Z","iopub.execute_input":"2024-09-10T01:34:37.904656Z","iopub.status.idle":"2024-09-10T01:34:37.918393Z","shell.execute_reply.started":"2024-09-10T01:34:37.904623Z","shell.execute_reply":"2024-09-10T01:34:37.917267Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Create Model","metadata":{}},{"cell_type":"markdown","source":"- CNN Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # 1st CNN layer\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 2)\n\n        # 2nd CNN layer\n        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 2)\n\n        # Max Pooling layer\n        self.max_pool = nn.MaxPool2d(kernel_size = 2)\n\n        # Mean Pooling layer\n        self.avg_pool = nn.AvgPool2d(kernel_size = 2)\n\n        # Fully Connected layer\n        self.fc = nn.Linear(in_features = 64 * 4 * 4, out_features = 2)\n\n    def forward(self, x):\n        x = self.max_pool(F.relu(self.conv1(x)))\n        x = self.max_pool(F.relu(self.conv2(x)))\n        x = self.avg_pool(x)\n        x = x.view(-1, 64 * 4 * 4) # flattening\n        x= self.fc(x)\n        return x ","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.919902Z","iopub.execute_input":"2024-09-10T01:34:37.920182Z","iopub.status.idle":"2024-09-10T01:34:37.932953Z","shell.execute_reply.started":"2024-09-10T01:34:37.920151Z","shell.execute_reply":"2024-09-10T01:34:37.931929Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device) # device = GPU","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.934320Z","iopub.execute_input":"2024-09-10T01:34:37.934674Z","iopub.status.idle":"2024-09-10T01:34:37.950649Z","shell.execute_reply.started":"2024-09-10T01:34:37.934637Z","shell.execute_reply":"2024-09-10T01:34:37.949717Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"markdown","source":"**Set Loss Function**","metadata":{}},{"cell_type":"code","source":"# loss function -> use cross entropy (because it's classification problem)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.954076Z","iopub.execute_input":"2024-09-10T01:34:37.954828Z","iopub.status.idle":"2024-09-10T01:34:37.960290Z","shell.execute_reply.started":"2024-09-10T01:34:37.954774Z","shell.execute_reply":"2024-09-10T01:34:37.959437Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"**Set Optimizer**","metadata":{}},{"cell_type":"code","source":"# optimizer -> finding optimized weight algorithm\n# SGD -> standard optimizer (use stochastic gradient descent)\n\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.01)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.961496Z","iopub.execute_input":"2024-09-10T01:34:37.961723Z","iopub.status.idle":"2024-09-10T01:34:37.973009Z","shell.execute_reply.started":"2024-09-10T01:34:37.961695Z","shell.execute_reply":"2024-09-10T01:34:37.972014Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Train Model**","metadata":{}},{"cell_type":"markdown","source":"- Process of Deep Learning Model Traning for images\n    1. Fetch data of batch size from data loader\n    2. Allocate given image and label(target) data to device(GPU)\n    3. Initialize gradient of Optimizer\n    4. Give input data (img) to CNN model -> forward propagation -> get output (predicted value)\n    5. Compare predicted value and label (target) value to calculate loss\n    6. Perform back propagation based on loss\n    7. Update weight using gradient calculated by back prop\n    8. Repeat 1~7 * (repeat count)\n    9. Repeat 1~8 * (epoch count)","metadata":{}},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    \n    for images, labels in loader_train: # repeat count = len(loader_train)\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        \n        loss = criterion(outputs, labels)\n        \n        epoch_loss += loss.item()\n        loss.backward()\n        \n        optimizer.step() # new weight = original weight - (learning rate * gradient)\n        \n    print(f'epoch [{epoch+1}/{epochs}] - loss: {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:34:37.974826Z","iopub.execute_input":"2024-09-10T01:34:37.975266Z","iopub.status.idle":"2024-09-10T01:37:39.042076Z","shell.execute_reply.started":"2024-09-10T01:34:37.975218Z","shell.execute_reply":"2024-09-10T01:37:39.041006Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"epoch [1/10] - loss: 0.5240\nepoch [2/10] - loss: 0.3407\nepoch [3/10] - loss: 0.2444\nepoch [4/10] - loss: 0.1975\nepoch [5/10] - loss: 0.1747\nepoch [6/10] - loss: 0.1637\nepoch [7/10] - loss: 0.1515\nepoch [8/10] - loss: 0.1430\nepoch [9/10] - loss: 0.1353\nepoch [10/10] - loss: 0.1287\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Performance Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nimport numpy as np\n\ntrue_list = []\npreds_list = []","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:52:18.325161Z","iopub.execute_input":"2024-09-10T01:52:18.325560Z","iopub.status.idle":"2024-09-10T01:52:18.331026Z","shell.execute_reply.started":"2024-09-10T01:52:18.325520Z","shell.execute_reply":"2024-09-10T01:52:18.330017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"model.eval() # evaluation stage -> won't apply dropout \n\nwith torch.no_grad(): # inactivate calculating gradient (no need to calculate gradient in evaluation step)\n    for images, labels in loader_valid:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        # why back to cpu? -> roc_auc is sklearn -> it can't perform on GPU\n        preds = torch.softmax(outputs.cpu(), dim = 1)[:, 1] # preds probability\n        true = labels.cpu() # true val\n        \n        # have to convert preds and true tensors to original python array or numpy array\n        preds_list.extend(preds.numpy())\n        true_list.extend(true.numpy())\n        \nprint(f'validation data ROC AUC: {roc_auc_score(true_list, preds_list):.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T01:52:36.144264Z","iopub.execute_input":"2024-09-10T01:52:36.144627Z","iopub.status.idle":"2024-09-10T01:52:37.384571Z","shell.execute_reply.started":"2024-09-10T01:52:36.144579Z","shell.execute_reply":"2024-09-10T01:52:37.383532Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"validation data ROC AUC: 0.9900\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Prediction and Submit Result","metadata":{}},{"cell_type":"code","source":"# create test dataset and data loader\ndataset_test = ImageDataset(df = submission, img_dir = 'test/', transform = transform)\nloader_test = DataLoader(dataset = dataset_test, batch_size = 32, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T02:00:28.462738Z","iopub.execute_input":"2024-09-10T02:00:28.463069Z","iopub.status.idle":"2024-09-10T02:00:28.468789Z","shell.execute_reply.started":"2024-09-10T02:00:28.463033Z","shell.execute_reply":"2024-09-10T02:00:28.467846Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\npreds = []\n\nwith torch.no_grad():\n    for images, _ in loader_test:\n        images = images.to(device)\n        \n        outputs = model(images)\n        \n        preds_part = torch.softmax(outputs.cpu(), dim = 1)[:, 1].tolist()\n        \n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T02:02:21.188918Z","iopub.execute_input":"2024-09-10T02:02:21.189249Z","iopub.status.idle":"2024-09-10T02:02:23.943029Z","shell.execute_reply.started":"2024-09-10T02:02:21.189212Z","shell.execute_reply":"2024-09-10T02:02:23.942226Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T02:03:06.787064Z","iopub.execute_input":"2024-09-10T02:03:06.787382Z","iopub.status.idle":"2024-09-10T02:03:06.821747Z","shell.execute_reply.started":"2024-09-10T02:03:06.787342Z","shell.execute_reply":"2024-09-10T02:03:06.820756Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# delete entire directory \nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2024-09-10T02:03:45.839010Z","iopub.execute_input":"2024-09-10T02:03:45.839369Z","iopub.status.idle":"2024-09-10T02:03:46.691211Z","shell.execute_reply.started":"2024-09-10T02:03:45.839327Z","shell.execute_reply":"2024-09-10T02:03:46.690344Z"},"trusted":true},"execution_count":50,"outputs":[]}]}